{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "302b2f86",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "California’s overall graduation rate hides important gaps for English learners, students with disabilities, and foster youth. This project develops a school-level Early Warning System (EWS) that identifies high schools at risk of low graduation rates using only publicly available data compliant with the Family Education Rights and Privacy Act (FERPA). Multiple statewide datasets, including ACGR, chronic absenteeism, FRPM eligibility, and staffing, were combined and aligned with the ABC framework. A Random Forest model achieved strong performance (PR-AUC = 0.78) and identified attendance, socioeconomic indicators, and still-enrolled rates as the strongest predictors. The results show that publicly available data can approximate traditional EWS insights and support scalable, privacy-preserving approaches to identifying emerging graduation-risk patterns.\n",
    "\n",
    "<br>\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Abstract](main_notebook.ipynb#abstract)\n",
    "2. [Business Background](main_notebook.ipynb#business-background)\n",
    "3. [Problem Statement](main_notebook.ipynb#problem-statement)\n",
    "4. [Summary of Findings](main_notebook.ipynb#summary-of-findings)\n",
    "5. [Business Questions](main_notebook.ipynb#business-questions)\n",
    "6. [Scope of Analysis](main_notebook.ipynb#scope-of-analysis)\n",
    "7. [Approach](main_notebook.ipynb#approach)\n",
    "8. [Limitations](main_notebook.ipynb#limitations)\n",
    "9. [Solution Details](main_notebook.ipynb#solution-details)\n",
    "10. [Concluding Summary](main_notebook.ipynb#concluding-summary)\n",
    "11. [Call to Action](main_notebook.ipynb#call-to-action)\n",
    "12. [References](main_notebook.ipynb#references)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## Business Background\n",
    "\n",
    "Attaining a high school diploma significantly improves students’ long-term employment and economic opportunities, while students who do not graduate face greater barriers, such as limited job prospects and lower lifetime earnings (Krueger et al., 2015). Even though these impacts are well-documented, thousands of California students still drop out each year.\n",
    "\n",
    "In 2021–2022, California’s overall graduation rate was 87%, measured using the four-year Adjusted Cohort Graduation Rate (ACGR). However, statewide averages hide important differences: groups such as English learners, students with disabilities, and foster youth continue to graduate at rates below 80%, a trend that has remained consistent over time (California Department of Education, 2023).\n",
    "\n",
    "To help identify emerging dropout risks, a lot of districts use Early Warning Systems (EWS) that track the “ABC” indicators: attendance, behavior, and course performance. Research shows that these models can effectively predict dropout risk (O’Cummings & Therriault, 2015; Rumberger et al., 2017). However, traditional EWS rely on student-level data that is protected under FERPA, making statewide scaling difficult.\n",
    "\n",
    "These gaps highlight the need for tools that can scale, protect student privacy, and still provide a way to identify schools where graduation rates may be starting to decline.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "California continues to see large graps in graduation rates, especially for English learners, foster youth, and students with disabilities. While statewide accountability tools such as the California School Dashboard report historical outcomes, they do not identify emerging risk factors or predict which schools may experience declining graduation rates.\n",
    "\n",
    "District-level Early Warning Systems exist, but they rely on restricted student-level data protected under FERPA, which limits access for researchers, policymakers, and education stakeholders. As a result, California does not have a scalable, publicly accessible method for assessing school-level graduation risk.\n",
    "\n",
    "This project addresses this gap by developing a predictive model using only publicly available school-level datasets from the California Department of Education. By aligning open data with the ABC early-warning framework, the model aims to identify high schools at risk of graduating fewer than 90% of their students while maintaining full compliance with data privacy requirements.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Summary of Findings\n",
    "\n",
    "- **Random Forest** achieved the strongest performance (PR-AUC = 0.78), with Logistic Regression and Naive Bayes close behind.\n",
    "- The most influential predictors aligned with the ABC framework:\n",
    "  - **Attendance:** chronic absenteeism, unexcused absences\n",
    "  - **Behavior/Course performance:** still-enrolled rate, A–G completion\n",
    "  - **Socioeconomic factors:** FRPM eligibility\n",
    "  - **Support indicators:** teacher experience and staffing patterns\n",
    "- Climate variables (CalSCHLS) did not meaningfully contribute to prediction and were excluded due to missingness.\n",
    "- A 90% graduation-rate threshold produced a manageable class distribution and allowed consistent risk identification without resampling.\n",
    "- Results confirm that public, non-PII school-level data can approximate the predictive insights of student-level Early Warning Systems.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Business Questions\n",
    "\n",
    "This project is guided by the following core questions:\n",
    "\n",
    "1. **Signal & prediction**\n",
    "\n",
    "   - To what extent can publicly available, school-level data from the California Department of Education (CDE) be used to predict whether a high school is at risk of graduating fewer than 90% of its students?\n",
    "\n",
    "2. **Key drivers**\n",
    "\n",
    "   - Which school-level indicators, especially those aligned with the Attendance, Behavior, and Course performance (ABC) framework, are most strongly associated with low graduation outcomes?\n",
    "\n",
    "3. **Equity & disproportionality**\n",
    "\n",
    "   - How do attendance, socioeconomic, and staffing patterns relate to graduation disparities for schools serving higher proportions of historically underserved students?\n",
    "\n",
    "4. **Model performance & reliability**\n",
    "\n",
    "   - Among commonly used classification algorithms, which models provide the most reliable performance on imbalanced graduation outcomes when trained solely on open, school-level data?\n",
    "\n",
    "5. **Practical deployment**\n",
    "\n",
    "   - Can the final model be deployed as an accessible, interactive tool (e.g., via a Streamlit application) that allows education leaders to explore predicted graduation risk and understand the factors driving those predictions?\n",
    "\n",
    "6. **Scalability & replication**\n",
    "   - Does this approach provide a scalable, privacy-preserving template that could be adapted to additional years or other states using similar publicly reported education data?\n",
    "\n",
    "<br>\n",
    "\n",
    "## Scope of Analysis\n",
    "\n",
    "This analysis focuses on developing a school-level Early Warning System (EWS) for predicting low graduation outcomes using only publicly available California Department of Education (CDE) datasets. The scope includes both the elements incorporated into the study and those intentionally excluded to ensure data quality, methodological consistency, and compliance with FERPA.\n",
    "\n",
    "### Included in Scope\n",
    "\n",
    "- **School-level data only:**  \n",
    "  All predictors were drawn from publicly accessible CDE reporting systems for the 2021–22 academic year.\n",
    "- **Multiple statewide datasets combined:**\n",
    "  Graduation outcomes (ACGR), absenteeism, student poverty (FRPM), staffing and teacher experience, enrollment, and school directory files were merged to create a unified school-level dataset. County-level school climate indicators (CalSCHLS 2017–19) were reviewed, though ultimately excluded from the final model.\n",
    "- **ABC Framework alignment:**  \n",
    "  Attendance, Behavior, and Course performance indicators were prioritized for modeling.\n",
    "- **High school population:**  \n",
    "  The analysis includes California public high schools with valid cohort sizes and complete graduation outcomes.\n",
    "- **Binary risk classification:**  \n",
    "  Schools were labeled “At Risk” if their graduation rate was below 90%, providing an early-warning threshold rather than a failing benchmark.\n",
    "- **Multiple machine learning models:**  \n",
    "  Seven supervised classification algorithms were tested and compared using imbalance-appropriate metrics (precision, recall, F1, PR-AUC).\n",
    "\n",
    "### Excluded from Scope\n",
    "\n",
    "- **Student-level data:**  \n",
    "  FERPA-protected records and individual student indicators were excluded entirely.\n",
    "- **Schools without valid ACGR data:**  \n",
    "  Schools missing graduation rates or reporting fewer than 90% of expected cohort enrollment were removed for data quality.\n",
    "- **Limited climate data availability:**  \n",
    "  The most recent CalSCHLS climiate indicators (2017-2019) were explored during EDA, but excluded from the final model because seven counties did not have any data and the variables did not improve predictive performance.\n",
    "- **Non-high school institutions:**  \n",
    "  Middle schools, continuation schools, juvenile court schools, and alternative education programs were excluded.\n",
    "- **Model optimization:**  \n",
    "  Hyperparameter tuning was not performed; models were compared using baseline settings to evaluate feasibility rather than maximize performance.\n",
    "\n",
    "### Scope Rationale\n",
    "\n",
    "Limiting the analysis to publicly available school-level data ensures full compliance with state and federal privacy regulations while supporting scalability, transparency, and reproducibility. Excluding datasets with significant missingness or limited predictive value helps maintain the reliability of the final model. Overall, the scope is designed to answer the core question of whether open, non-sensitive data can provide early-warning insights traditionally derived from student-level systems.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Approach\n",
    "\n",
    "The development of a school-level Early Warning System (EWS) followed a structured, multi-stage process aligned with best practices in data preparation, exploratory analysis, and supervised machine learning. The goal was to determine whether publicly available CDE datasets could reliably predict graduation risk while remaining fully compliant with FERPA.\n",
    "\n",
    "### 1. Data Acquisition and Integration\n",
    "\n",
    "Multiple publicly accessible CDE reporting systems were used to build the unified school-level dataset, including graduation outcomes (ACGR), chronic absenteeism, FRPM eligibility, staffing and teacher experience, enrollment, and school directory files. Each dataset was cleaned, standardized, and merged using the 14-digit CDS code as the unique school identifier. Records were filtered to retain only California public high schools with valid cohort data and active reporting status.\n",
    "\n",
    "### 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA was performed to assess distributions, detect anomalies, and evaluate missingness. Patterns were reviewed across attendance, coursework, staffing, and socioeconomic indicators. We examined skewness, outliers, and correlations to understand the relationships between predictors and graduation outcomes. Class imbalance was confirmed, with most schools reporting high graduation rates.\n",
    "\n",
    "### 3. Data Quality Assessment\n",
    "\n",
    "Variables with inconsistent reporting, low variance, or structural missingness were flagged for removal. CalSCHLS climate indicators were explored but excluded because data were missing for seven counties and the variables did not improve model performance. Remaining missing values in staffing and enrollment fields were imputed using median values.\n",
    "\n",
    "### 4. Feature Engineering\n",
    "\n",
    "Feature selection and engineering focused on strengthening alignment with the ABC framework. Non-informative and redundant variables (e.g., climate-connectedness indicators, geographic identifiers, low-variance categories) were removed. A binary target variable was constructed using a 90% graduation-rate threshold to support early-warning risk classification. The final modeling dataset included the 15 strongest predictors identified through Random Forest importance rankings.\n",
    "\n",
    "### 5. Model Development and Evaluation\n",
    "\n",
    "Seven supervised learning algorithms were trained for comparison: Logistic Regression, Naive Bayes, Random Forest, Support Vector Machine (SVM), K Nearest Neighbors (KNN), Decision Tree, and XGBoost. An 80/20 stratified split was used to address class imbalance. Model performance was evaluated using precision, recall, F1 score, and PR-AUC, since accuracy is not meaningful for imbalanced outcomes. No synthetic resampling methods were applied; instead, stratification and class weighting were used to ensure fair evaluation. The Random Forest model achieved the highest PR-AUC (0.78) and demonstrated the most consistent performance across thresholds.\n",
    "\n",
    "### 6. Deployment and Visualization\n",
    "\n",
    "To support practical adoption, the final model was integrated into an interactive Streamlit application that allows users to adjust key indicators and view real-time predictions. The app also summarizes predictor importance, enabling education leaders to interpret contributing factors and explore risk scenarios for California high schools.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Limitations\n",
    "\n",
    "While this study demonstrates that school-level, publicly available data can be used to predict low graduation outcomes, several limitations should be considered when interpreting results and applying the model.\n",
    "\n",
    "### 1. Limited Availability of School-Climate Data\n",
    "\n",
    "School climate and safety indicators from CalSCHLS were only available at the county level for 2017–2019, and data were missing for seven counties. Since these indicators did not improve model performance, they were excluded. Consequently, the model does not fully incorporate behavioral or engagement-related climate factors that influence graduation outcomes.\n",
    "\n",
    "### 2. Constraints of School-Level Aggregation\n",
    "\n",
    "The analysis uses aggregated, school-level indicators rather than student-level data. While appropriate for privacy and scalability, school-level variables cannot capture individual patterns of disengagement, subgroup differences, or student-level pathways that may contribute to graduation disparities.\n",
    "\n",
    "### 3. FERPA-Driven Data Suppression\n",
    "\n",
    "Several CDE reporting systems suppress outcomes for small subgroups to protect student privacy. This results in structural missingness in certain fields—especially absenteeism subgroups and low-frequency indicators—which may limit model granularity.\n",
    "\n",
    "### 4. Limited Generalizability Beyond California\n",
    "\n",
    "The model is designed specifically for California’s reporting structure, data availability, and accountability framework. States with different data systems or different definitions of graduation metrics may require adjustments to replicate this approach.\n",
    "\n",
    "### 5. Class Imbalance and Model Baseline Scope\n",
    "\n",
    "Because most California high schools graduate more than 90% of students, the dataset is inherently imbalanced. Although PR-AUC and class weighting mitigate this, rare-at-risk schools may be harder to identify. Additionally, models were compared using baseline settings rather than full hyperparameter optimization, as the goal was feasibility rather than maximum performance.\n",
    "\n",
    "Despite these limitations, the findings provide evidence that open, school-level data can serve as a practical foundation for scalable, privacy-preserving early warning analytics across California high schools.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Solution Details\n",
    "\n",
    "The resulting Early Warning System (EWS) provides a scalable, privacy-preserving approach for identifying California public high schools at risk of low graduation outcomes. Built entirely from publicly available school-level data, the system offers a practical alternative to traditional student-level EWS models that are restricted under FERPA and difficult to implement consistently across districts.\n",
    "\n",
    "### A Simplified, School-Level Predictive Model\n",
    "\n",
    "The final solution is a supervised machine learning model trained on multiple publicly available CDE reporting systems aligned with the Attendance, Behavior, and Course performance (ABC) framework. A Random Forest classifier was selected as the primary model because it achieved the strongest performance on imbalanced outcomes (PR AUC = 0.78) and provided interpretable feature rankings.\n",
    "\n",
    "The model uses 15 key predictors, including chronic absenteeism, unexcused absences, FRPM eligibility, still enrolled rates, A-G completion, student teacher ratios, and teacher experience. Together, these indicators offer a streamlined and effective approach to identifying schools that may be at risk of lower graduation outcomes.\n",
    "\n",
    "### Actionable Insights Through Predictor Importance\n",
    "\n",
    "Feature importance analysis highlights the main drivers of school level graduation outcomes and aligns closely with well established early warning research. Attendance and engagement indicators were the strongest predictors, followed by socioeconomic and course completion measures. A fourth category also emerged in our analysis: School Support, reflected in factors such as teacher experience and staffing related measures at the school level.\n",
    "\n",
    "These insights give school and district leaders a clearer understanding of the conditions most associated with lower graduation outcomes and help guide where early and targeted interventions may be needed.\n",
    "\n",
    "### Interactive Risk Exploration Tool\n",
    "\n",
    "To support practical adoption, the solution includes a publicly accessible Streamlit web application that allows users to:\n",
    "\n",
    "- adjust key school indicators using interactive sliders,\n",
    "- view real-time risk predictions based on the final Random Forest model,\n",
    "- examine the relative importance of predictors,\n",
    "- explore results without any need for coding or specialized software.\n",
    "\n",
    "This tool provides an intuitive, user-friendly interface that districts, county offices, and policymakers can use to understand potential risk patterns and test “what-if” scenarios.\n",
    "\n",
    "### Scalable and Replicable Framework\n",
    "\n",
    "Because the system relies only on school-level, non-PII data that is released annually by the CDE, it can be easily updated for future school years and adapted for additional states with similar public reporting structures. The workflow is fully documented and reproducible, ensuring transparency and enabling districts to validate and extend the model as needed.\n",
    "\n",
    "Overall, the solution demonstrates that publicly available data can support reliable early-warning insights while maintaining privacy, equity, and accessibility—key priorities for California’s education system.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Concluding Summary\n",
    "\n",
    "This project demonstrates that a simplified, school-level Early Warning System (EWS) can reliably identify California public high schools at risk of low graduation outcomes using only publicly available, non-PII data. By integrating multiple statewide datasets aligned with the ABC framework and evaluating seven supervised learning algorithms, we showed that publicly reported school indicators can approximate the predictive insights typically achieved using restricted student-level systems. The final Random Forest model delivered strong performance on imbalanced outcomes (PR-AUC = 0.78) and identified key predictors consistent with established research, including chronic absenteeism, unexcused absences, FRPM eligibility, and course-completion measures.\n",
    "\n",
    "Importantly, the project provides an equitable and scalable framework for early-warning analytics across California’s diverse school system. Because the model relies exclusively on open data, it can be updated annually, replicated across districts, and adapted for use in other states with similar reporting structures while remaining fully compliant with federal privacy regulations.\n",
    "\n",
    "Combined with an interactive Streamlit application that allows users to explore risk scenarios and examine predictor importance, this solution offers a practical foundation for supporting early intervention, guiding resource allocation, and strengthening educational outcomes in California’s public high schools.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Call to Action\n",
    "\n",
    "Education leaders, district administrators, researchers, and policymakers are encouraged to use the resources developed in this project to support data-informed decision-making and strengthen graduation outcomes across California high schools.\n",
    "\n",
    "To explore the model and its insights:\n",
    "\n",
    "- **Use the interactive Early Warning System application** to adjust key school indicators and view real-time risk predictions:  \n",
    "  https://ca-early-warning-system.streamlit.app/\n",
    "\n",
    "- **Review the full workflow, modeling code, and documentation** in the project’s GitHub repository to understand how the model was built, evaluated, and deployed.\n",
    "\n",
    "- **Leverage the identified predictors**, especially chronic absenteeism, unexcused absences, FRPM eligibility, and A–G completion, to guide targeted interventions, resource allocation, and equity-focused planning.\n",
    "\n",
    "- **Adapt and extend the framework** for additional school years, district-level analyses, or for use in other states with similar publicly reported data.\n",
    "\n",
    "By engaging with these tools and insights, stakeholders can take actionable steps toward earlier identification of emerging risks, more strategic support for high-need schools, and more equitable educational outcomes across California.\n",
    "\n",
    "<br>\n",
    "\n",
    "## References\n",
    "\n",
    "Austin, G., Hanson, T., Bala, N., & Zheng, C. (2023). Student engagement and well-being in California, 2019-21: Results of the Eighteenth Biennial State California Healthy Kids Survey, Grades 7, 9, and 11. WestEd. https://data.calschls.org/resources/18th_Biennial_State_1921.pdf\n",
    "\n",
    "California Department of Education. (n.d.). Retrieved October 26, 2025, from https://www.cde.ca.gov/\n",
    "\n",
    "Chen, T., Wanberg, R. C., Gouioa, E. T., Brown, M. J. S., Chen, J. C.-Y., & Kurt Kraiger, J. J. (2019). Engaging parents Involvement in K – 12 Online Learning Settings: Are We Meeting the Needs of Underserved Students? Journal of E-Learning and Knowledge Society, Vol 15 No 2 (2019): Journal of eLearning and Knowledge Society. https://doi.org/10.20368/1971-8829/1563\n",
    "\n",
    "Cobb, C. D. (2020). Geospatial Analysis: A New Window Into Educational Equity, Access, and Opportunity. Review of Research in Education, 44(1), 97–129. https://doi.org/10.3102/0091732X20907362\n",
    "\n",
    "Rumberger, R., Addis, H., Allensworth, E., Balfanz, R., Bruch, J., Dillon, E., Duardo, D., Dynarski, M., Furgeson, J., Jayanthi, M., Newman-Gonchar, R., Place, K., & Tuttle, C. (2017). Preventing Dropout in Secondary Schools (No. NCEE 2017-4028). National Center for Education Evaluation and Regional Assistance (NCEE), Institute of Education Sciences, U.S. Department of Education. https://whatworks.ed.gov\n",
    "\n",
    "Sava, S., Bunoiu, M., & Malita, L. (2017). Ways to Improve Students’ Decision for Academic Studies. Acta Didactica Napocensia, 10(4), 109–120. https://doi.org/10.24193/adn.10.4.11\n",
    "\n",
    "Siegle, D., Gubbins, E. J., O’Rourke, P., Langley, S. D., Mun, R. U., Luria, S. R., Little, C. A., McCoach, D. B., Knupp, T., Callahan, C. M., & Plucker, J. A. (2016). Barriers to Underserved Students’ Participation in Gifted Programs and Possible Solutions. Journal for the Education of the Gifted, 39(2), 103–131. https://doi.org/10.1177/0162353216640930\n",
    "\n",
    "The California School Climate, Health, and Learning Survey (CalSCHLS) System—Home. (n.d.). Retrieved October 26, 2025, from https://calschls.org/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
