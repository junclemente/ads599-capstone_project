{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "302b2f86",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "California’s overall graduation rate masks substantial disparities for English learners, students with disabilities, and foster youth. This project develops a school-level Early Warning System (EWS) that identifies high schools at risk of low graduation rates using only publicly available, FERPA-compliant data. Four statewide datasets—ACGR, chronic absenteeism, FRPM eligibility, and staffing—were combined and aligned with the ABC framework. A Random Forest model achieved strong performance (PR-AUC = 0.78) and identified attendance, socioeconomic indicators, and still-enrolled rates as the strongest predictors. The results show that publicly available data can approximate traditional EWS insights and support scalable, privacy-preserving approaches to identifying emerging graduation-risk patterns.\n",
    "\n",
    "<br>\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Abstract](#Abstract)\n",
    "2. [Business Background](#Business-Background)\n",
    "3. [Problem Statement](#Problem-Statement)\n",
    "4. [Summary of Findings](#Summary-of-Findings)\n",
    "5. [Business Questions](#Business-Questions)\n",
    "6. [Scope of Analysis](#Scope-of-Analysis)\n",
    "7. [Approach](#Approach)\n",
    "8. [Limitations](#Limitations)\n",
    "9. [Solution Details](#Solution-Details)\n",
    "10. [Concluding Summary](#Concluding-Summary)\n",
    "11. [Call to Action](#Call-To-Action)\n",
    "12. [References](#References)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Business Background\n",
    "\n",
    "Attaining a high school diploma significantly improves students’ long-term employment and economic opportunities, while students who do not graduate face greater barriers, including limited job prospects and lower lifetime earnings (Krueger et al., 2015). Despite these well-documented impacts, thousands of California students continue to drop out each year.\n",
    "\n",
    "In 2021–2022, California’s overall graduation rate was 87%, measured using the four-year Adjusted Cohort Graduation Rate (ACGR). However, statewide averages mask persistent disparities: groups such as English learners, students with disabilities, and foster youth continue to graduate at rates below 80%, a trend that has remained consistent over time (California Department of Education, 2023).\n",
    "\n",
    "To help identify emerging dropout risks, many districts use Early Warning Systems (EWS) that track the “ABC” indicators—attendance, behavior, and course performance. Research shows that these models can effectively predict dropout risk (O’Cummings & Therriault, 2015; Rumberger et al., 2017). However, traditional EWS rely on student-level data that is protected under FERPA, making statewide scaling difficult.\n",
    "\n",
    "These persistent gaps underscore the need for scalable, privacy-preserving approaches that leverage publicly available data to support early identification of schools where graduation outcomes may be declining.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "California continues to experience persistent disparities in graduation outcomes, particularly among English learners, foster youth, and students with disabilities. While statewide accountability tools such as the California School Dashboard report historical outcomes, they do not identify emerging risk factors or predict which schools may experience declining graduation rates.\n",
    "\n",
    "District-level Early Warning Systems exist, but they rely on restricted student-level data protected under FERPA, limiting access for researchers, policymakers, and education stakeholders. As a result, California lacks a scalable, publicly accessible method for assessing school-level graduation risk.\n",
    "\n",
    "This project addresses this gap by developing a predictive model using only publicly available school-level datasets from the California Department of Education. By aligning open data with the ABC early-warning framework, the model aims to identify high schools at risk of graduating fewer than 90% of their students while maintaining full compliance with data privacy requirements.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Summary of Findings\n",
    "\n",
    "- **Random Forest** achieved the strongest performance (PR-AUC = 0.78), with Logistic Regression and Naive Bayes close behind.\n",
    "- The most influential predictors aligned with the ABC framework:\n",
    "  - **Attendance:** chronic absenteeism, unexcused absences\n",
    "  - **Behavior/Course performance:** still-enrolled rate, A–G completion\n",
    "  - **Socioeconomic factors:** FRPM eligibility\n",
    "  - **Support indicators:** teacher experience and staffing patterns\n",
    "- Climate variables (CalSCHLS) did **not** meaningfully contribute to prediction and were excluded due to missingness.\n",
    "- A 90% graduation-rate threshold produced a manageable class distribution and allowed consistent risk identification without resampling.\n",
    "- Results confirm that **public, non-PII school-level data** can approximate the predictive insights of student-level Early Warning Systems.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Business Questions\n",
    "\n",
    "This project is guided by the following core questions:\n",
    "\n",
    "1. **Signal & prediction**\n",
    "\n",
    "   - To what extent can publicly available, school-level data from the California Department of Education (CDE) be used to predict whether a high school is at risk of graduating fewer than 90% of its students?\n",
    "\n",
    "2. **Key drivers**\n",
    "\n",
    "   - Which school-level indicators—particularly those aligned with the Attendance, Behavior, and Course performance (ABC) framework—are most strongly associated with low graduation outcomes?\n",
    "\n",
    "3. **Equity & disproportionality**\n",
    "\n",
    "   - How do attendance, socioeconomic, and staffing patterns relate to graduation disparities for schools serving higher proportions of historically underserved students?\n",
    "\n",
    "4. **Model performance & reliability**\n",
    "\n",
    "   - Among commonly used classification algorithms, which models provide the most reliable performance on imbalanced graduation outcomes when trained solely on open, school-level data?\n",
    "\n",
    "5. **Practical deployment**\n",
    "\n",
    "   - Can the final model be deployed as an accessible, interactive tool (e.g., via a Streamlit application) that allows education leaders to explore predicted graduation risk and understand the factors driving those predictions?\n",
    "\n",
    "6. **Scalability & replication**\n",
    "   - Does this approach provide a scalable, privacy-preserving template that could be adapted to additional years or other states using similar publicly reported education data?\n",
    "\n",
    "<br>\n",
    "\n",
    "## Scope of Analysis\n",
    "\n",
    "This analysis focuses on developing a school-level Early Warning System (EWS) for predicting low graduation outcomes using only publicly available California Department of Education (CDE) datasets. The scope includes both the elements incorporated into the study and those intentionally excluded to ensure data quality, methodological consistency, and compliance with FERPA.\n",
    "\n",
    "### Included in Scope\n",
    "\n",
    "- **School-level data only:**  \n",
    "  All predictors were drawn from publicly accessible CDE reporting systems for the 2021–22 academic year.\n",
    "- **Four aligned statewide datasets:**\n",
    "  - Adjusted Cohort Graduation Rate (ACGR)\n",
    "  - Chronic Absenteeism\n",
    "  - Free/Reduced-Price Meal (FRPM) eligibility\n",
    "  - CBEDS Staff Assignment (teacher/staff characteristics)\n",
    "- **ABC Framework alignment:**  \n",
    "  Attendance, Behavior, and Course performance indicators were prioritized for modeling.\n",
    "- **High school population:**  \n",
    "  The analysis includes California public high schools with valid cohort sizes and complete graduation outcomes.\n",
    "- **Binary risk classification:**  \n",
    "  Schools were labeled “At Risk” if their graduation rate was below 90%, providing an early-warning threshold rather than a failing benchmark.\n",
    "- **Multiple machine learning models:**  \n",
    "  Seven supervised classification algorithms were tested and compared using imbalance-appropriate metrics (precision, recall, F1, PR-AUC).\n",
    "\n",
    "### Excluded from Scope\n",
    "\n",
    "- **Student-level data:**  \n",
    "  FERPA-protected records and individual student indicators were excluded entirely.\n",
    "- **Schools without valid ACGR data:**  \n",
    "  Schools missing graduation rates or reporting fewer than 90% of expected cohort enrollment were removed for data quality.\n",
    "- **Outdated or incomplete climate data:**  \n",
    "  County-level CalSCHLS indicators from 2017–2019 were excluded from the final model due to missingness for seven counties and misalignment with 2021–22 data.\n",
    "- **Non-high school institutions:**  \n",
    "  Middle schools, continuation schools, juvenile court schools, and alternative education programs were excluded.\n",
    "- **Model optimization:**  \n",
    "  Hyperparameter tuning was not performed; models were compared using baseline settings to evaluate feasibility rather than maximize performance.\n",
    "\n",
    "### Scope Rationale\n",
    "\n",
    "Limiting the analysis to publicly available school-level data ensures full compliance with state and federal privacy regulations while enabling scalability, transparency, and reproducibility. Excluding temporally misaligned or incomplete datasets preserves the integrity of the modeling process. The scope supports the core objective of determining whether open data can approximate early-warning insights traditionally derived from student-level systems.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Approach\n",
    "\n",
    "The development of a school-level Early Warning System (EWS) followed a structured, multi-stage process aligned with best practices in data preparation, exploratory analysis, and supervised machine learning. The goal was to determine whether publicly available CDE datasets could reliably predict graduation risk while remaining fully compliant with FERPA.\n",
    "\n",
    "### 1. Data Acquisition and Integration\n",
    "\n",
    "Five publicly accessible CDE reporting systems were collected for the 2021–22 academic year: ACGR, Chronic Absenteeism, FRPM eligibility, CBEDS Staffing, and the School Directory. Each dataset was cleaned, standardized, and merged using the 14-digit CDS code as the unique school identifier. Records were filtered to include only California public high schools with valid cohort data.\n",
    "\n",
    "### 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA was performed to assess distributions, detect anomalies, and evaluate missingness. Patterns were reviewed across attendance, coursework, staffing, and socioeconomic indicators. We examined skewness, outliers, and correlations to understand the relationships between predictors and graduation outcomes. Class imbalance was confirmed, with most schools reporting high graduation rates.\n",
    "\n",
    "### 3. Data Quality Assessment\n",
    "\n",
    "Variables with inconsistent reporting, low variance, or structural missingness were identified. School-climate and safety indicators from CalSCHLS (2017–2019) were initially merged but later excluded due to missingness for seven counties and misalignment with the 2021–22 datasets. Remaining missing values in staffing and enrollment features were imputed using median values to preserve sample size.\n",
    "\n",
    "### 4. Feature Engineering\n",
    "\n",
    "Feature selection and engineering focused on strengthening alignment with the ABC framework. Non-informative and redundant variables (e.g., climate-connectedness indicators, geographic identifiers, low-variance categories) were removed. A binary target variable was constructed using a 90% graduation-rate threshold to support early-warning risk classification. The final modeling dataset included the 15 strongest predictors identified through Random Forest importance rankings.\n",
    "\n",
    "### 5. Model Development and Evaluation\n",
    "\n",
    "Seven supervised learning algorithms—Logistic Regression, Naive Bayes, Random Forest, SVM, KNN, Decision Tree, and XGBoost—were trained using an 80/20 stratified split to account for imbalance. Models were evaluated using precision, recall, F1 score, and PR-AUC, as accuracy is not meaningful for imbalanced outcomes. No synthetic resampling was applied; instead, class weighting and stratification ensured fair evaluation. The Random Forest model achieved the highest PR-AUC (0.78) and consistent performance across thresholds.\n",
    "\n",
    "### 6. Deployment and Visualization\n",
    "\n",
    "To support practical adoption, the final model was integrated into an interactive Streamlit application that allows users to adjust key indicators and view real-time predictions. The app also summarizes predictor importance, enabling education leaders to interpret contributing factors and explore risk scenarios for California high schools.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Limitations\n",
    "\n",
    "While this study demonstrates that school-level, publicly available data can be used to predict low graduation outcomes, several limitations should be considered when interpreting results and applying the model.\n",
    "\n",
    "### 1. Limited Availability of School-Climate Data\n",
    "\n",
    "School climate and safety indicators from the CalSCHLS survey were only available at the county level and for earlier years (2017–2019). Missing data for seven counties and misalignment with the 2021–22 academic year prevented these variables from being included in the final model. As a result, the model does not fully reflect behavioral or engagement-related climate conditions that are known to influence graduation outcomes.\n",
    "\n",
    "### 2. Constraints of School-Level Aggregation\n",
    "\n",
    "The analysis uses aggregated, school-level indicators rather than student-level data. While appropriate for privacy and scalability, school-level variables cannot capture individual patterns of disengagement, subgroup differences, or student-level pathways that may contribute to graduation disparities.\n",
    "\n",
    "### 3. FERPA-Driven Data Suppression\n",
    "\n",
    "Several CDE reporting systems suppress outcomes for small subgroups to protect student privacy. This results in structural missingness in certain fields—especially absenteeism subgroups and low-frequency indicators—which may limit model granularity.\n",
    "\n",
    "### 4. Limited Generalizability Beyond California\n",
    "\n",
    "The model is designed specifically for California’s reporting structure, data availability, and accountability framework. States with different data systems or different definitions of graduation metrics may require adjustments to replicate this approach.\n",
    "\n",
    "### 5. Class Imbalance and Model Baseline Scope\n",
    "\n",
    "Because most California high schools graduate more than 90% of students, the dataset is inherently imbalanced. Although PR-AUC and class weighting mitigate this, rare-at-risk schools may be harder to identify. Additionally, models were compared using baseline settings rather than full hyperparameter optimization, as the goal was feasibility rather than maximum performance.\n",
    "\n",
    "Despite these limitations, the findings provide evidence that open, school-level data can serve as a practical foundation for scalable, privacy-preserving early warning analytics across California high schools.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Solution Details\n",
    "\n",
    "The resulting Early Warning System (EWS) provides a scalable, privacy-preserving approach for identifying California public high schools at risk of low graduation outcomes. Built entirely from publicly available school-level data, the system offers a practical alternative to traditional student-level EWS models that are restricted under FERPA and difficult to implement consistently across districts.\n",
    "\n",
    "### A Simplified, School-Level Predictive Model\n",
    "\n",
    "The final solution is a supervised machine learning model trained on four statewide CDE datasets aligned with the Attendance, Behavior, and Course performance (ABC) framework. A Random Forest classifier was selected as the primary model based on its strong performance on imbalanced outcomes (PR-AUC = 0.78) and its ability to provide interpretable feature rankings. The model uses 15 key predictors— including chronic absenteeism, unexcused absences, FRPM eligibility, still-enrolled rates, A–G completion, and teacher experience—offering a streamlined yet powerful approach to forecasting graduation risk.\n",
    "\n",
    "### Actionable Insights Through Predictor Importance\n",
    "\n",
    "Feature importance analysis highlights the underlying drivers of school-level graduation disparities and mirrors well-established early-warning research. Attendance and engagement indicators emerged as the strongest predictors, followed by socioeconomic and course-completion measures. These insights offer school and district leaders a clear starting point for identifying conditions associated with lower graduation outcomes and prioritizing interventions.\n",
    "\n",
    "### Interactive Risk Exploration Tool\n",
    "\n",
    "To support practical adoption, the solution includes a publicly accessible Streamlit web application that allows users to:\n",
    "\n",
    "- adjust key school indicators using interactive sliders,\n",
    "- view real-time risk predictions based on the final Random Forest model,\n",
    "- examine the relative importance of predictors,\n",
    "- explore results without any need for coding or specialized software.\n",
    "\n",
    "This tool provides an intuitive, user-friendly interface that districts, county offices, and policymakers can use to understand potential risk patterns and test “what-if” scenarios.\n",
    "\n",
    "### Scalable and Replicable Framework\n",
    "\n",
    "Because the system relies only on school-level, non-PII data that is released annually by the CDE, it can be easily updated for future school years and adapted for additional states with similar public reporting structures. The workflow is fully documented and reproducible, ensuring transparency and enabling districts to validate and extend the model as needed.\n",
    "\n",
    "Overall, the solution demonstrates that publicly available data can support reliable early-warning insights while maintaining privacy, equity, and accessibility—key priorities for California’s education system.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Concluding Summary\n",
    "\n",
    "This project demonstrates that a simplified, school-level Early Warning System (EWS) can reliably identify California public high schools at risk of low graduation outcomes using only publicly available, non-PII data. By integrating multiple statewide datasets aligned with the ABC framework and evaluating seven supervised learning algorithms, we showed that publicly reported school indicators can approximate the predictive insights typically achieved using restricted student-level systems. The final Random Forest model delivered strong performance on imbalanced outcomes (PR-AUC = 0.78) and identified key predictors consistent with established research, including chronic absenteeism, unexcused absences, FRPM eligibility, and course-completion measures.\n",
    "\n",
    "Importantly, the project provides an equitable and scalable framework for early-warning analytics across California’s diverse school system. Because the model relies exclusively on open data, it can be updated annually, replicated across districts, and adapted for use in other states with similar reporting structures—all while remaining fully compliant with federal privacy regulations.\n",
    "\n",
    "Combined with an interactive Streamlit application that allows users to explore risk scenarios and examine predictor importance, this solution offers a practical foundation for supporting early intervention, guiding resource allocation, and strengthening educational outcomes in California’s public high schools.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Call to Action\n",
    "\n",
    "Education leaders, district administrators, researchers, and policymakers are encouraged to use the resources developed in this project to support data-informed decision-making and strengthen graduation outcomes across California high schools.\n",
    "\n",
    "To explore the model and its insights:\n",
    "\n",
    "- **Use the interactive Early Warning System application** to adjust key school indicators and view real-time risk predictions:  \n",
    "  https://ca-early-warning-system.streamlit.app/\n",
    "\n",
    "- **Review the full workflow, modeling code, and documentation** in the project’s GitHub repository to understand how the model was built, evaluated, and deployed.\n",
    "\n",
    "- **Leverage the identified predictors**—particularly chronic absenteeism, unexcused absences, FRPM eligibility, and A–G completion—to guide targeted interventions, resource allocation, and equity-focused planning.\n",
    "\n",
    "- **Adapt and extend the framework** for additional school years, district-level analyses, or for use in other states with similar publicly reported data.\n",
    "\n",
    "By engaging with these tools and insights, stakeholders can take actionable steps toward earlier identification of emerging risks, more strategic support for high-need schools, and more equitable educational outcomes across California.\n",
    "\n",
    "<br>\n",
    "\n",
    "## References\n",
    "\n",
    "Austin, G., Hanson, T., Bala, N., & Zheng, C. (2023). Student engagement and well-being in California, 2019-21: Results of the Eighteenth Biennial State California Healthy Kids Survey, Grades 7, 9, and 11. WestEd. https://data.calschls.org/resources/18th_Biennial_State_1921.pdf\n",
    "\n",
    "California Department of Education. (n.d.). Retrieved October 26, 2025, from https://www.cde.ca.gov/\n",
    "\n",
    "Chen, T., Wanberg, R. C., Gouioa, E. T., Brown, M. J. S., Chen, J. C.-Y., & Kurt Kraiger, J. J. (2019). Engaging parents Involvement in K – 12 Online Learning Settings: Are We Meeting the Needs of Underserved Students? Journal of E-Learning and Knowledge Society, Vol 15 No 2 (2019): Journal of eLearning and Knowledge Society. https://doi.org/10.20368/1971-8829/1563\n",
    "\n",
    "Cobb, C. D. (2020). Geospatial Analysis: A New Window Into Educational Equity, Access, and Opportunity. Review of Research in Education, 44(1), 97–129. https://doi.org/10.3102/0091732X20907362\n",
    "\n",
    "Rumberger, R., Addis, H., Allensworth, E., Balfanz, R., Bruch, J., Dillon, E., Duardo, D., Dynarski, M., Furgeson, J., Jayanthi, M., Newman-Gonchar, R., Place, K., & Tuttle, C. (2017). Preventing Dropout in Secondary Schools (No. NCEE 2017-4028). National Center for Education Evaluation and Regional Assistance (NCEE), Institute of Education Sciences, U.S. Department of Education. https://whatworks.ed.gov\n",
    "\n",
    "Sava, S., Bunoiu, M., & Malita, L. (2017). Ways to Improve Students’ Decision for Academic Studies. Acta Didactica Napocensia, 10(4), 109–120. https://doi.org/10.24193/adn.10.4.11\n",
    "\n",
    "Siegle, D., Gubbins, E. J., O’Rourke, P., Langley, S. D., Mun, R. U., Luria, S. R., Little, C. A., McCoach, D. B., Knupp, T., Callahan, C. M., & Plucker, J. A. (2016). Barriers to Underserved Students’ Participation in Gifted Programs and Possible Solutions. Journal for the Education of the Gifted, 39(2), 103–131. https://doi.org/10.1177/0162353216640930\n",
    "\n",
    "The California School Climate, Health, and Learning Survey (CalSCHLS) System—Home. (n.d.). Retrieved October 26, 2025, from https://calschls.org/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
